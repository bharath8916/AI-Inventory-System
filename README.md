# AI-Inventory-System


## âœ¨ Highlights

* **Forecasting:** Probabilistic demand forecasts (daily/weekly) per SKU/location with confidence intervals.
* **Vision:** Optional camera/phone-based **image capture** for shelf counts via object detection + OCR (UPC/QR).
* **Replenishment:** Smart reorder points & purchase order suggestions based on lead time and service levels.
* **Anomalies:** Automatic stockout/overstock detection, shrinkage alerts, and outlier sales cleanup.
* **Ops Copilot:** Naturalâ€‘language Q&A over inventory, creating POs, and explaining forecasts.
* **APIs & UI:** REST + WebSocket APIs, Admin dashboard, and webhook integrations.
* **Batteries included:** AuthN/Z, migrations, seeding, background jobs, metrics, tracing, and tests.



---

## ğŸ— Architecture

```
[Clients]
  â”œâ”€ Web Admin (React/Next.js)
  â”œâ”€ Mobile (Expo/React Native)
  â””â”€ Integrations (Webhooks)

[API Gateway]
  â””â”€ FastAPI (Python) / NestJS (Node)  â† REST + WS
      â”œâ”€ Auth Service (JWT/OAuth2)
      â”œâ”€ Inventory Service
      â”œâ”€ Orders/PO Service
      â”œâ”€ Forecast Service (ML)
      â””â”€ Vision Service (CV)

[Async]
  â”œâ”€ Task Queue (Celery/RQ/BullMQ)
  â””â”€ Message Bus (Redis/Kafka)

[Data]
  â”œâ”€ PostgreSQL (OLTP)
  â””â”€ Object Store (S3/MinIO)


```

* **Scales down** to a single `docker-compose` for local dev.
* **Scales up** to Kubernetes with horizontal autoscaling.

---

## ğŸ§° Tech Stack

* **Backend:** Python 3.11, FastAPI, SQLModel/SQLAlchemy, Pydantic
* **Workers:** Celery + Redis (scheduling, ETL, training, notifications)
* **Forecasting:** Prophet / ARIMA / LightGBM (hierarchical reconciliation via MinT)
* **Vision:** Tesseract/EasyOCR for OCR
* **DB/Storage:** PostgreSQL.
* **Auth:** OAuth2+OIDC (Auth0/Keycloak) or local JWT
* **Frontend:** Next.js 14 (App Router), Tailwind, TanStack Query, shadcn/ui
* **Infra:** Docker, dockerâ€‘compose, Make, GitHub Actions, Helm/ArgoCD


---

## ğŸ“ Repository Layout

```
AI-Inventory-System/
â”œâ”€ apps/
â”‚  â”œâ”€ api/                # FastAPI app (routers, schemas, services)
â”‚  â”œâ”€ worker/             # Celery worker tasks (ETL, training, alerts)
â”‚  â””â”€ web/                # Next.js admin dashboard
â”œâ”€ packages/
â”‚  â”œâ”€ ml/                 # Forecasting & feature pipelines
â”‚  â””â”€ vision/             # Detection models & inference server
â”œâ”€ infra/
â”‚  â”œâ”€ docker/             # Dockerfiles
â”‚  â”œâ”€ compose/            # docker-compose.yml
â”‚  â””â”€ k8s/                # Helm charts & manifests
â”œâ”€ migrations/            # Alembic migrations
â”œâ”€ seeds/                 # Example data
â”œâ”€ .env.example
â”œâ”€ Makefile
â”œâ”€ pyproject.toml
â””â”€ README.md
```

---

## ğŸš€ Quickstart

### 1) Prerequisites

* Docker 24+
* Docker Compose v2
* Make (optional but recommended)

### 2) Clone & Configure

```bash
git clone https://github.com/<your-org>/AI-Inventory-System.git
cd AI-Inventory-System
cp .env.example .env
# edit .env as needed
```

### 3) Oneâ€‘liner (Docker Compose)

```bash
make up
# or
docker compose -f infra/compose/docker-compose.yml up -d --build
```

> API: [http://localhost:8000](http://localhost:8000)  â€¢  Docs: [http://localhost:8000/docs](http://localhost:8000/docs)  â€¢  Web: [http://localhost:3000](http://localhost:3000)

### 4) Seed Data (optional)

```bash
make seed
# or
python scripts/seed.py
```

### 5) Run Tests

```bash
make test
# or
pytest -q
```

---

## âš™ï¸ Configuration

Environment variables (copy from `.env.example`):

```ini
# core
APP_ENV=dev
SECRET_KEY=change-me

# database
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_DB=inventory
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres

# redis / queue
REDIS_URL=redis://redis:6379/0

# object storage
S3_ENDPOINT=http://minio:9000
S3_ACCESS_KEY=minioadmin
S3_SECRET_KEY=minioadmin
S3_BUCKET=ai-inventory

# auth
OAUTH_ISSUER=
OAUTH_CLIENT_ID=
OAUTH_CLIENT_SECRET=
JWT_EXPIRES_IN=3600

# forecasting
FORECAST_FREQ=D
FORECAST_HORIZON=28
SERVICE_LEVEL=0.95

```

> For production, set unique secrets, enable HTTPS, and use managed Postgres/S3.

---

## ğŸ“Š Data & Modeling

### Entities

* **Product (SKU)**, **Location**, **InventoryLevel**, **Transaction** (receipts, sales, adjustments), **PurchaseOrder**, **Supplier**.

### Forecasting Pipeline

1. Ingest sales & calendar/price features
2. Clean outliers, impute missing days, reconcile hierarchies (SKUâ†’Categoryâ†’Location)
3. Fit base models (Prophet/ARIMA/LightGBM)
4. Blend & calibrate quantiles (P10/P50/P90)
5. Emit forecasts â†’ `forecasts` table & parquet snapshots

**Safety stock** `SS = z * Ïƒ_LT` and **ROP** `ROP = Î¼_LT + SS` where leadâ€‘time parameters come from supplier SLAs.

### Vision Pipeline (optional)

* Upload image via UI or API â†’ detect SKUs â†’ tally counts â†’ suggest adjustments if variance > threshold.

---

## ğŸ“š API Reference

Base URL: `http://localhost:8000`

### Auth

* `POST /auth/login` â€“ Email/Password â†’ JWT
* `GET /auth/me` â€“ Current user

### Inventory

* `GET /inventory` â€“ List items (filters: `sku`, `location_id`, `in_stock`)
* `GET /inventory/{id}` â€“ Get item
* `POST /inventory` â€“ Create/adjust levels
* `POST /inventory/reconcile` â€“ Bulk recount upload (CSV/images)

### Orders

* `GET /orders` â€“ List POs
* `POST /orders` â€“ Create purchase order (autoâ€‘suggest from forecasts)
* `PATCH /orders/{id}` â€“ Update status

### Forecasts

* `GET /forecasts?sku=&location_id=&horizon=` â€“ Quantile forecasts
* `POST /forecasts/retrain` â€“ Trigger model retrain (async)

### Webhooks

* `POST /webhooks/sales` â€“ Ingest sales
* `POST /webhooks/erp` â€“ Sync products/locations

> Explore interactive docs at **`/docs`** (Swagger) and **`/redoc`**.

---

## ğŸ§µ Background Jobs

* **Nightly retraining:** refresh models if accuracy drops
* **PO suggestions:** generate vendorâ€‘grouped reorders
* **Anomaly alerts:** shrinkage/stockout alerts to Slack/Email
* **ETL:** import CSVs from S3, normalize, and load

Schedule examples (Celery beat):

```yaml
beat_schedule:
  retrain_daily: { task: ml.retrain_all, schedule: "0 2 * * *" }
  suggest_pos:   { task: ops.generate_pos, schedule: "0 6 * * 1-6" }
```




---

## â˜ï¸ Deployment

### Docker Compose (prodâ€‘like)

```bash
docker compose -f infra/compose/docker-compose.yml --env-file .env up -d
```

### Kubernetes (Helm)

```bash
helm upgrade --install ai-inventory infra/k8s/chart \
  --set image.tag=$(git rev-parse --short HEAD) \
  --values infra/k8s/values.prod.yaml
```

### Database Migrations

```bash
alembic upgrade head
```



---

## ğŸ¤ Contributing

1. Fork the repo & create a feature branch
2. Run tests & linters: `make ci`
3. Open a PR with a clear description and screenshots

Please read `CODE_OF_CONDUCT.md` and `CONTRIBUTING.md`.

---



## ğŸ™Œ Acknowledgements

* Inspired by best practices from retail ops & MLOps communities

